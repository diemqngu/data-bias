#Data Bias

To begin my data analysis, I established that the threshold for toxicity would be a score that is greater than 0.5. I determined this after parsing through the data and noticing that comments I perceived as neutral comments were typically below 0.5. Unless comments were explicitly nice and utilized phrases with positive connotations, such as, "I love you" or "Thank you!," the API would still score a neutral phrase pretty high on the toxicity scale. Conversely, I noticed that many comments that I found to be pretty offensive were given scores within the 0.4-0.5 range, which indicates that the API believed the comment was only slightly offensive or not that offensive at all. Because of this discrepancy, I believed it would be best to choose 0.5 as the toxicity threshold because the scores ranged from 0 to 1 on a decimal scale and 0 to 100 on a percentage scale and 0.5 is directly at the center of that range. Additionally, the Perspective API documentation states that their algorithms are based on 'raters' that they hire to view a list of comments and rate the toxicity of, meaning that a lot of the phrases are only marked oddly because of differing opinions between the mass amount of raters hired for this job. Overall, the API seems to be very advanced and sophisticated and I did not see that many false negatives or positives in general. I did see issues with labeling, especially in the insult and identity_hate labels.

The hypothesis I tested was to see if the Perspective API has any bias toward gender. I tested this by specifically utilizing gendered parental nouns (mom/mother/mommy, dad/father/daddy) in comments. I took phrases commonly seen on social media and replaced the noun with the opposing noun. I played around with several variations of mom and dad, and the outcome, though slight, always leaned in the male pronouns' favor. Upon running my tests, it was evident that in every case, comments containing female pronouns were considered more offensive than comments containing male pronouns. This indicates a bias towards women, and I believe it is rooted in the fact that most countries still have heavily patriarchal societies, where men are respected far more than women. It isn't very surprising because women are the butt of many jokes commonly used on social media. 

The Perspective API machine learning algorithm is based on data collected from the 'raters' that they hired. I believe it is safe to assume that the machine learning algorithm developed this bias due to the bias of the raters. This brings attention to machine learning as a whole, and how data scientists should work to create an algorithm that is fair and ensure that their test subjects, in this case, the raters, should be screened for bias before being considered as a data point in a bigger project that has societal relevance.
